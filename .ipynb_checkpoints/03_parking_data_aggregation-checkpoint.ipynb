{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parking Data aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba para 1 dataset (proceso descriptivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         _id  recvTimeTs             recvTime          entityId  attrValue\n",
      "0     222747  1594637257  2020-07-13T10:47:37  Aparcamiento:101         46\n",
      "1     222748  1594637498  2020-07-13T10:51:38  Aparcamiento:101         51\n",
      "2     222749  1594637618  2020-07-13T10:53:38  Aparcamiento:101         52\n",
      "3     222750  1594637738  2020-07-13T10:55:38  Aparcamiento:101         49\n",
      "4     222751  1594637858  2020-07-13T10:57:38  Aparcamiento:101         55\n",
      "...      ...         ...                  ...               ...        ...\n",
      "7038  229785  1596235592  2020-07-31T22:46:32  Aparcamiento:101        316\n",
      "7039  229786  1596235953  2020-07-31T22:52:33  Aparcamiento:101        317\n",
      "7040  229787  1596236673  2020-07-31T23:04:33  Aparcamiento:101        316\n",
      "7041  229788  1596236793  2020-07-31T23:06:33  Aparcamiento:101        319\n",
      "7042  229789  1596239553  2020-07-31T23:52:33  Aparcamiento:101        320\n",
      "\n",
      "[7043 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# leemos el dataset para ver su formato\n",
    "df = pd.read_csv('./data/parkings_JULIO/101Libertad.csv', sep=\";\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-13 10:47:37\n"
     ]
    }
   ],
   "source": [
    "# transformamos una de sus fechas de string a fecha\n",
    "datetime_str = '2020-07-13T10:47:37'\n",
    "datetime_object = datetime.strptime(datetime_str, '%Y-%m-%dT%H:%M:%S')\n",
    "print(datetime_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         _id  recvTimeTs            recvTime          entityId  attrValue\n",
      "0     222747  1594637257 2020-07-13 10:47:37  Aparcamiento:101         46\n",
      "1     222748  1594637498 2020-07-13 10:51:38  Aparcamiento:101         51\n",
      "2     222749  1594637618 2020-07-13 10:53:38  Aparcamiento:101         52\n",
      "3     222750  1594637738 2020-07-13 10:55:38  Aparcamiento:101         49\n",
      "4     222751  1594637858 2020-07-13 10:57:38  Aparcamiento:101         55\n",
      "...      ...         ...                 ...               ...        ...\n",
      "7038  229785  1596235592 2020-07-31 22:46:32  Aparcamiento:101        316\n",
      "7039  229786  1596235953 2020-07-31 22:52:33  Aparcamiento:101        317\n",
      "7040  229787  1596236673 2020-07-31 23:04:33  Aparcamiento:101        316\n",
      "7041  229788  1596236793 2020-07-31 23:06:33  Aparcamiento:101        319\n",
      "7042  229789  1596239553 2020-07-31 23:52:33  Aparcamiento:101        320\n",
      "\n",
      "[7043 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# creamos un parser para leer bien las fechas\n",
    "def parser(x):\n",
    "    return datetime.strptime(x, '%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "df = pd.read_csv('./data/parkings_JULIO/101Libertad.csv', sep=\";\", parse_dates=[2], date_parser=parser)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recvTime\n",
      "2020-07-13 10:00:00     52.000000\n",
      "2020-07-13 11:00:00    104.500000\n",
      "2020-07-13 12:00:00    171.708333\n",
      "2020-07-13 13:00:00    196.080000\n",
      "2020-07-13 14:00:00    169.692308\n",
      "                          ...    \n",
      "2020-07-31 19:00:00    251.592593\n",
      "2020-07-31 20:00:00    285.235294\n",
      "2020-07-31 21:00:00    301.875000\n",
      "2020-07-31 22:00:00    313.500000\n",
      "2020-07-31 23:00:00    318.333333\n",
      "Freq: H, Name: attrValue, Length: 446, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agregamos los datos por horas usando la media\n",
    "df2 = df.set_index('recvTime').resample('H').mean()\n",
    "# interpolamos los valores faltantes\n",
    "# The method data.interpolate accepts the input parameter limit, which defines the maximum number of consecutive NaNs to be substituted by interpolation.\n",
    "df3 = df2['attrValue'].interpolate(limit=6)\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def parser(x):\n",
    "    return datetime.strptime(x, '%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "def read_and_resample(datapath, interp = 0):\n",
    "    df = pd.read_csv(datapath, sep=\";\", parse_dates=[2], date_parser=parser)\n",
    "    df2 = df.set_index('recvTime').resample('H').mean()\n",
    "    if(interp!=0):\n",
    "        df3 = df2['attrValue'].interpolate(limit=interp)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacemos el resample y agregamos los datasets por zonas y fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lavega = read_and_resample('./data/parkings_JULIO/102LaVega.csv')\n",
    "lavega_inter = lavega['attrValue'].interpolate()\n",
    "lavega_inter.to_csv(\"./data/parkings_JULIO/lavega_inter.csv\",sep=\";\",index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(446, 4)\n",
      "(446, 3)\n",
      "                           free\n",
      "recvTime                       \n",
      "2020-07-13 10:00:00  167.363636\n",
      "2020-07-13 11:00:00  246.157895\n",
      "2020-07-13 12:00:00  351.465909\n",
      "2020-07-13 13:00:00  404.080000\n",
      "2020-07-13 14:00:00  362.413238\n",
      "...                         ...\n",
      "2020-07-31 19:00:00  512.900285\n",
      "2020-07-31 20:00:00  554.235294\n",
      "2020-07-31 21:00:00  572.875000\n",
      "2020-07-31 22:00:00  586.000000\n",
      "2020-07-31 23:00:00  592.333333\n",
      "\n",
      "[446 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Zona 1: La Vega y La libertad -- espacio total = 312 + 330 = 642\n",
    "lavega = read_and_resample('./data/parkings_JULIO/102LaVega.csv')\n",
    "print(lavega.shape) # tiene una columna más, llena de NaNs que ignoramos\n",
    "libertad = read_and_resample('./data/parkings_JULIO/101Libertad.csv')\n",
    "print(libertad.shape)\n",
    "merge=libertad.merge(lavega, how='inner', on='recvTime')\n",
    "merge['free'] = merge['attrValue_x'] + merge['attrValue_y']\n",
    "zone1 = merge[[ 'free']]\n",
    "print(zone1)\n",
    "zone1.to_csv(\"./data/parkings_JULIO/zone1.csv\",sep=\";\",index=True)\n",
    "# to do: comprobar por qué hay tantos vacíos y si cuando no coinciden los huecos, directamente no aparece\n",
    "# el problema podría ser que se sumara a cero, ver que no pasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(412, 4)\n",
      "(302, 4)\n",
      "(446, 4)\n",
      "                     free\n",
      "recvTime                 \n",
      "2020-07-19 00:00:00   NaN\n",
      "2020-07-19 01:00:00   NaN\n",
      "2020-07-19 02:00:00   NaN\n",
      "2020-07-19 03:00:00   NaN\n",
      "2020-07-19 04:00:00   NaN\n",
      "...                   ...\n",
      "2020-07-30 09:00:00   NaN\n",
      "2020-07-30 10:00:00   NaN\n",
      "2020-07-30 11:00:00   NaN\n",
      "2020-07-30 12:00:00   NaN\n",
      "2020-07-30 13:00:00   NaN\n",
      "\n",
      "[278 rows x 1 columns]\n",
      "(278, 1)\n"
     ]
    }
   ],
   "source": [
    "# Zona 2.1: Alfonso X + CentroFama + MoralesMeseguer -- espacio total = 305 + 162+ 220 = 687\n",
    "\n",
    "alfonsox = read_and_resample('./data/parkings_JULIO/103AlfonsoX.csv')\n",
    "print(alfonsox.shape) # tiene una columna más, llena de NaNs que ignoramos\n",
    "centrofama = read_and_resample('./data/parkings_JULIO/104Centrofama.csv')\n",
    "print(centrofama.shape)\n",
    "mm = read_and_resample('./data/parkings_JULIO/105MoralesMeseguer.csv')\n",
    "print(mm.shape)\n",
    "merge1=alfonsox.merge(centrofama, how='inner', on='recvTime')\n",
    "merge2=merge1.merge(mm, how='inner', on='recvTime')\n",
    "merge2['free'] = merge2['attrValue_x'] + merge2['attrValue_y'] + merge2['attrValue']\n",
    "zone2_1 = merge2[[ 'free']]\n",
    "print(zone2_1)\n",
    "print(zone2_1.shape)\n",
    "zone2_1.isna().sum()\n",
    "# no coinciden las fechas de los datasets\n",
    "alfonsox.to_csv(\"./data/parkings_JULIO/alfonsox.csv\",sep=\";\",index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
